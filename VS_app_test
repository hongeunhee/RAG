# -*- coding: utf-8 -*-
"""
Created on Fri Jun  7 13:57:59 2024

@author: 202202871
"""

import streamlit as st
import os
import pandas as pd
import google.generativeai as genai
from IPython.display import Markdown, display
import textwrap
from ipaddress import ip_address
import re
from collections import Counter

# Start Streamlit app
st.set_page_config(page_title="Vulnerability Scanner: Analyze your weblog data", page_icon="ğŸ”")
st.title("ğŸ” Vulnerability Scanner: Analyze your weblog data")

folder_path = st.sidebar.text_input(label="File path", type="default")
gemini_api_key = st.sidebar.text_input(label="Gemini API Key", type="password",)
    
# Check user inputs
if not folder_path:
    st.info("Please enter the folder path for the weblog data in the sidebar.")
    st.stop()

if not gemini_api_key:
    st.info("Please add your Gemini API key to the sidebar to continue.")
    st.stop()
    
# Verify that the path entered is valid
if folder_path:
    if os.path.isdir(folder_path):
        st.write(f"Entered path: {folder_path}")
        st.write("Folder Content:")
        # Output a list of files and directories in a folder
        for item in os.listdir(folder_path):
            st.write(item)
    else:
        st.error("Please enter a valid folder path.")
else:
    st.write("Please enter your folder path.")

# Functions needed to automatically identify delimiters and column names for multiple txt files with different user input methods and convert them into a single panda data frame
def find_best_delimiter(lines):
    delimiters = [r'\s+', ',', ';', '\t']
    best_delimiter = None
    max_parts = 0

    for delim in delimiters:
        total_parts = sum(len(re.split(delim, line.strip())) for line in lines)
        if total_parts > max_parts:
            best_delimiter = delim
            max_parts = total_parts

    return best_delimiter

def auto_split(line, delimiter):
    parts = re.split(delimiter, line.strip())
    return parts

def parse_file(file_path):
    parsed_data = []
    try:
        with open(file_path, 'r') as file:
            lines = file.readlines()
            delimiter = find_best_delimiter(lines)
            for line in lines:
                parts = auto_split(line, delimiter)
                parsed_data.append(parts)
    except FileNotFoundError as e:
        print(f"File not found: {e.filename}")
    except Exception as e:
        print(f"An error occurred: {e}")

    return parsed_data

def parse_folder(folder_path):
    all_parsed_data = []
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        if not os.path.isfile(file_path) or not filename.endswith('.txt'):
            continue
        parsed_data = parse_file(file_path)
        all_parsed_data.extend(parsed_data)
    return all_parsed_data

def infer_column_names(parsed_lines):
    if not parsed_lines:
        return []

    ip_pattern = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b')
    date_pattern = re.compile(r'\[?\d{2}/\w{3}/\d{4}:\d{2}:\d{2}:\d{2}\]?')
    request_pattern = re.compile(r'\/[^\s]+')
    
    sample_line = parsed_lines[0]
    column_names = []

    for part in sample_line:
        if ip_pattern.match(part):
            column_names.append('ip_address')
        elif date_pattern.match(part):
            column_names.append('timestamp')
        elif request_pattern.match(part):
            column_names.append('request')
        elif part.isdigit() and len(part) == 3:
            column_names.append('status_code')
        elif part.isdigit() and 1 <= len(part) <= 4 or part == '-':
            column_names.append('size')
        else:
            column_names.append('unknown')
        
    counts = Counter(column_names)
    for i, name in enumerate(column_names):
        if counts[name] > 1:
            suffix = counts[name]
            column_names[i] = f'{name}_{suffix}'
            counts[name] -= 1

    return column_names

def parse_folder_to_dataframe(folder_path):
    parsed_data = parse_folder(folder_path)
    if not parsed_data:
        return pd.DataFrame()
    columns = infer_column_names(parsed_data) #ìë™ ì‹ë³„ ì–´ë ¤ìš¸ ë•Œ ì—´ì´ë¦„ ì‚¬ìš©ìì—ê²Œ ë°›ëŠ” ë¶€ë¶„ ì¶”ê°€í•´ì•¼ í•¨
    df = pd.DataFrame(parsed_data, columns=columns)
    #df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce') #í…ŒìŠ¤íŠ¸ í•´ë´ì•¼ í•¨
    df['timestamp'] = pd.to_datetime(df['timestamp'], format='[%d/%b/%Y:%H:%M:%S', errors='coerce') 
    dataframe = df.sort_values(by='timestamp', ascending=True)
    return dataframe
     
def filter_logs_within_1_minute(sorted_data):
    
    filtered_logs = []
    
    # ë°ì´í„°ë¥¼ ë°˜ë³µí•˜ë©´ì„œ í•„í„°ë§
    for i in range(len(sorted_data)):
        current_entry = sorted_data[i]
        current_datetime = current_entry['timestamp']
        current_ip = current_entry['ip_address']
        current_response_code = current_entry['status_code']
        
        # í˜„ì¬ ë¡œê·¸ê°€ '404' ì‘ë‹µ ì½”ë“œë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
        if current_response_code in ['404']:
            # ë‹¤ìŒ ë¡œê·¸ë¶€í„° 1ì´ˆ ì´ë‚´ì˜ ë¡œê·¸ë¥¼ í™•ì¸
            for j in range(i+1, len(sorted_data)):
                next_entry = sorted_data[j]
                next_datetime = next_entry['timestamp']
                next_ip = next_entry['ip_address']
                next_response_code = next_entry['status_code']
                
                # 1ì´ˆ ì´ë‚´ì˜ ë¡œê·¸ì´ê³  ë™ì¼í•œ IPì— ëŒ€í•´ '404'ì™€ '200' ì‘ë‹µ ì½”ë“œë¥¼ ê°€ì§€ê³  ìˆëŠ” ê²½ìš° í•„í„°ë§
                if (next_datetime - current_datetime).total_seconds() <= 1 and next_ip == current_ip and next_response_code in ['404', '200']:
                    filtered_logs.append(current_entry)
                    break
    
    return filtered_logs

def attacked_web_log(filtered_logs):
    # 1ì´ˆ ì´ë‚´ 404 í˜¹ì€ 200ì—ëŸ¬ 1000ê°œ ì´ˆê³¼ IP ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ   
    filtered_logs = pd.DataFrame(filtered_logs).sort_values(by='ip_address')
    ip_counts = pd.DataFrame(filtered_logs['ip_address'].value_counts())
    ip_counts.columns = ['count']
    atk_ip = ip_counts[ip_counts['count'] >= 1000]
    atk_ip_lst = atk_ip.index.to_list()
    # í•´ë‹¹ IPì— ëŒ€í•œ ì›¹ë¡œê·¸ ë°ì´í„°
    atk_info = dataframe[dataframe['ip_address'].isin(atk_ip_lst)]
    # ì¤‘ìš” íŒ¨í„´ì„ ê°€ì§„ ì›¹ë¡œê·¸ë§Œ í•„í„°ë§ 
    ptn_plt = atk_info[atk_info['request'].str.contains("' OR '1'='1|%|passwd|cgi-bin")]
    # ê³µê²©ì— ì„±ê³µí•œ ì›¹ë¡œê·¸ í•„í„°ë§
    ptn_plt.loc[:, 'status_code'] = ptn_plt.loc[:, 'status_code'].astype(int)
    atk_scs = ptn_plt[ptn_plt['status_code'].apply(lambda x: eval(f"x {'==200'}"))]
    scan_frt_day = atk_scs['timestamp'].iloc[0]
    atk_scs_count = len(atk_scs)
    
    # ìŠ¤ìº” ì´í›„ ë°ì´í„° ê°’ì—ì„œ ì‹ ê·œ IPì™€ ìŠ¤ìº” ê³¼ì •ì—ì„œ ì´ìƒ IPì— ëŒ€í•œ ë°ì´í„°ë§Œ í•„í„°ë§
    scan_lst_day = atk_scs['timestamp'].iloc[-1]
    scan_b4_ip = dataframe[dataframe['timestamp'] <= scan_lst_day]['ip_address'].unique().tolist()
    for i in atk_ip_lst:
        scan_b4_ip.remove(i)
    afs = dataframe[dataframe['timestamp'] > scan_lst_day]
    new_ip_info = afs.loc[~(afs['ip_address'].isin(scan_b4_ip))]

    # ResponseCode 200ì¸ ì†ŒìŠ¤ì½”ë“œ í•„í„°ë§
    new_ip_info.loc[:, 'status_code'] = new_ip_info.loc[:, 'status_code'].astype(int)
    new_ip_info_200 = new_ip_info[new_ip_info['status_code'].apply(lambda x: eval(f"x {'==200'}"))]
   
    # Sizeê°€ í‰ê· ì˜ 10ë°° ì´ìƒì¸ ì†ŒìŠ¤ì½”ë“œ í•„í„°ë§
    new_ip_info_200.loc[:, 'size'] = new_ip_info_200.loc[:, 'size'].astype(int)
    size_lst = new_ip_info_200['size'].tolist()
    size_avg = sum(size_lst)/len(size_lst)
    abnormal = new_ip_info_200[new_ip_info_200['size'] >= size_avg*10]

    atk_ip_count = len(atk_ip_lst)
    st.write(f"There are a total of {atk_ip_count} IPs used to scan vulnerabilities, and the IPs are as follows: {atk_ip_lst}")
    st.write(f"Vulnerability scan start point is {scan_frt_day} and end point is {scan_lst_day}. Hacker have scanned a total of {atk_scs_count} vulnerabilities.")
    
    return atk_scs, abnormal
    
def get_public_ips(ip_list):
    public_ips = []
    
    for ip in ip_list:
        if not is_private_ip(ip):
            public_ips.append(ip)
    
    return public_ips
 
# ì‚¬ì„¤ IP ì£¼ì†Œ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
def is_private_ip(ip):
    private_ip_ranges = [
("10.0.0.0", "10.255.255.255"),
("172.16.0.0", "172.31.255.255"),
("192.168.0.0", "192.168.255.255")
    ]
    
    for start, end in private_ip_ranges:
        if ip_address(start) <= ip_address(ip) <= ip_address(end):
            return True
    return False
 
#Create a helper function that will convert the markdwon into nicely formatted text
def to_markdown(text):
  return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))
 
if __name__=="__main__":
    
    dataframe = parse_folder_to_dataframe(folder_path)    
    dic_df = dataframe.to_dict(orient='records')
    
    # ì´ìƒ íƒì§€í•œ ì›¹ë¡œê·¸ ì¶œë ¥
    filtered_logs = filter_logs_within_1_minute(dic_df)
    
    ### ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ë‹¨ê³„ ###
    # gemini-agent êµ¬ì„±
    #api_key = 'AIzaSyAij_2eLy-nzQVRDouKKur-1TfObHYi3E8' 
    genai.configure(api_key = gemini_api_key) #transport='' The user can pass a string to choose 'rest' or 'grpc' or 'grpc_asyncio'
    model = genai.GenerativeModel("models/gemini-1.5-pro-latest")
    ### ê¸°ë³¸ ì¶œë ¥ ###
    atk_scs, abnormal = attacked_web_log(filtered_logs)
    ### ì·¨ì•½ì  ìŠ¤ìº” ê¸°ê°„ ë™ì•ˆì˜ í˜ì´ë¡œë“œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ###
    st.write("The results of the payload analysis during the hacker's vulnerability scan are as follows.")
    lst = atk_scs['request'].tolist()
    response = model.generate_content(f"{lst}: Please analyze those payloads")
    st.write(response)
    ### ì·¨ì•½ì  ìŠ¤ìº” ì´í›„ í˜ì´ë¡œë“œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ###
    st.write("The following is the result of the payload analysis after the hacker's vulnerability scan.")
    pay_lst = abnormal['request'].tolist()
    response = model.generate_content(f"{pay_lst}: Please analyze the payloads. If there's nothing special, let me know there isn't")
    st.write(response)
    st.write("In addition, this is the result of an analysis of API security vulnerabilities after the vulnerability scan.")
    response = model.generate_content(f"{pay_lst}: Please let me know if there are any vulnerabilities that correspond to OWASP API security TOP10. If there is nothing special, please let me know there are none")
    st.write(response)



