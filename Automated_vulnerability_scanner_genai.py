# -*- coding: utf-8 -*-
"""
Created on Wed May 9 15:34:23 2024
This code works if you have weblog data. 
This code finds more than 1,000 consecutive IPs in one second at the same time with each responsesecode value of 404 or 200. 
Next, the generative ai model analyzes the payload of the hacker's vulnerability scan period 
and the payload of the attack after the vulnerability scan. It can even analyze API vulnerability attacks.
@author: Hui, Hong
"""
#Import all the required libraries
import os
import pandas as pd
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
#from dotenv import load_dotenv # Save gemini-pro api key, If necessary, fill out the relevant code and use it

def merge_text_files_to_dataframe(folder_path):
    # Collect all text files within a folder
    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.txt')]
    
    # Merge all text files into one data frame
    parsed_data = []
    columns = ['IP', 'NV1', 'NV2', 'DateTime', 'NV3', 'Request1', 'Request2', 'Protocol', 'ResponseCode', 'Size']

    for file_path in file_paths:
        with open(file_path, 'r') as file:
            for line in file:
                parts = line.split(' ')
                parsed_row = dict(zip(columns, parts))
                parsed_data.append(parsed_row)

    # Converting to pandas dataFrame
    df = pd.DataFrame(parsed_data)
    # Sort data frame by 'DateTime' column
    df['DateTime'] = df['DateTime'].apply(lambda x: x.replace ('[',''))
    df['DateTime'] = pd.to_datetime(df['DateTime'], format="%d/%b/%Y:%H:%M:%S")
    df.sort_values(by='DateTime', inplace=True)
    return df
 
def filter_logs_within_1_minute(sorted_data):
    
    filtered_logs = []
    
    # Filtering while repeating
    for i in range(len(sorted_data)):
        current_entry = sorted_data[i]
        current_datetime = current_entry['DateTime']
        current_ip = current_entry['IP']
        current_response_code = current_entry['ResponseCode']
        
        # Determine if the current log has a '404' response code
        if current_response_code in ['404']:
            # Check the log within 1 second from the next log
            for j in range(i+1, len(sorted_data)):
                next_entry = sorted_data[j]
                next_datetime = next_entry['DateTime']
                next_ip = next_entry['IP']
                next_response_code = next_entry['ResponseCode']
                
                # 1초 이내의 로그이고 동일한 IP에 대해 '404'와 '200' 응답 코드를 가지고 있는 경우 필터링
                if (next_datetime - current_datetime).total_seconds() <= 1 and next_ip == current_ip and next_response_code in ['404', '200']:
                    filtered_logs.append(current_entry)
                    break
    
    return filtered_logs

def attacked_web_log(filtered_logs):
    # 1초 이내 404 혹은 200에러 1000개 초과 IP 리스트 추출   
    filtered_logs = pd.DataFrame(filtered_logs).sort_values(by='IP')
    ip_counts = pd.DataFrame(filtered_logs['IP'].value_counts())
    ip_counts.columns = ['count']
    atk_ip = ip_counts[ip_counts['count'] >= 1000]
    atk_ip_lst = atk_ip.index.to_list()
    # 해당 IP에 대한 웹로그 데이터
    atk_info = dataframe[dataframe['IP'].isin(atk_ip_lst)]
    # 중요 패턴을 가진 웹로그만 필터링 
    ptn_plt = atk_info[atk_info['Request2'].str.contains("' OR '1'='1|%|passwd|cgi-bin")]
    # 공격에 성공한 웹로그 필터링
    ptn_plt.loc[:, 'ResponseCode'] = ptn_plt.loc[:, 'ResponseCode'].astype(int)
    atk_scs = ptn_plt[ptn_plt['ResponseCode'].apply(lambda x: eval(f"x {'==200'}"))]
    scan_frt_day = atk_scs['DateTime'].iloc[0]
    atk_scs_count = len(atk_scs)
    
    # 스캔 이후 데이터 값에서 신규 IP와 스캔 과정에서 이상 IP에 대한 데이터만 필터링
    scan_lst_day = atk_scs['DateTime'].iloc[-1]
    scan_b4_ip = dataframe[dataframe['DateTime'] <= scan_lst_day]['IP'].unique().tolist()
    for i in atk_ip_lst:
        scan_b4_ip.remove(i)
    afs = dataframe[dataframe['DateTime'] > scan_lst_day]
    new_ip_info = afs.loc[~(afs['IP'].isin(scan_b4_ip))]
    # ResponseCode 200인 소스코드 필터링
    new_ip_info.loc[:, 'ResponseCode'] = new_ip_info.loc[:, 'ResponseCode'].astype(int)
    new_ip_info_200 = new_ip_info[new_ip_info['ResponseCode'].apply(lambda x: eval(f"x {'==200'}"))]
    # Size가 평균의 10배 이상인 소스코드 필터링
    new_ip_info_200.loc[:, 'Size'] = new_ip_info_200.loc[:, 'Size'].astype(int)
    size_lst = new_ip_info_200['Size'].tolist()
    size_avg = sum(size_lst)/len(size_lst)
    abnormal = new_ip_info_200[new_ip_info_200['Size'] >= size_avg*10]
    
    atk_ip_count = len(atk_ip_lst)
    print(f"취약점 스캔에 사용한 IP는 총 {atk_ip_count}개로 다음과 같습니다.: {atk_ip_lst} ")
    print(f"취약점 스캔 시작 시점은 {scan_frt_day}이고 종료 시점은 {scan_lst_day}입니다. 총 {atk_scs_count}번의 취약점을 스캔했습니다.")
    return atk_scs, abnormal

#Create a helper function that will convert the markdwon into nicely formatted text
def to_markdown(text):
  return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))
 
if __name__=="__main__":
    # 사용자로부터 폴더 경로 입력 받기
    folder_path = input("폴더 경로를 입력하세요: ")
    
    dataframe = merge_text_files_to_dataframe(folder_path)
    dic_df = dataframe.to_dict(orient='records')
    
    # 이상 탐지한 웹로그 출력
    filtered_logs = filter_logs_within_1_minute(dic_df)
    for log in filtered_logs:
        print(log)
        
    ### 분석 결과 출력 단계 ###
    # gemini-agent 구성
    user_input = input("gemini-api 키값을 입력하세요.")
    genai.configure(api_key = user_input) # transport = 'rest'. The user can pass a string to choose 'rest' or 'grpc' or 'grpc_asyncio'. If you use 'grpc_asyncio', you should run "conda install grpcio" in the conda prompt before using it.
    model = genai.GenerativeModel("models/gemini-1.5-pro-latest")
    ### 기본 출력 ###
    atk_scs, abnormal = attacked_web_log(filtered_logs)
    ### 취약점 스캔 기간 동안의 페이로드 분석 결과 출력 ###
    print("취약점 스캔 동안의 페이로드 분석 결과는 다음과 같습니다.")
    lst = atk_scs['Request2'].tolist()
    response = model.generate_content(f"{lst}: 해당 페이로드들을 분석해줘")
    display(to_markdown(response.text))

    ### 취약점 스캔 이후 페이로드 분석 결과 출력 ###
    print("다음은 취약점 스캔 이후 페이로드 분석 결과입니다.")
    pay_lst = abnormal['Request2'].tolist()
    response = model.generate_content(f"{pay_lst}: 페이로드를 분석해 줘. 특별한 점이 없으면 없다고 알려줘")
    display(to_markdown(response.text))
    ### 취약점 스캔 이후 API 보안 취약점 분석 결과 출력 ###
    print("다음은 API 보안 취약점에 대한 분석 결과입니다.")
    response = model.generate_content(f"{pay_lst}: OWASP API 보안 TOP10에 해당하는 취약점이 있으면 알려줘. 특별한 점이 없으면 없다고 알려줘")
    display(to_markdown(response.text))
